{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMi+uEK7s/sd5/RI43+qfdp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WEN0009/ADS2001/blob/main/Assignment_3_Part_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwgkVa_FGF_V"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.random.set_seed(6789)\n",
        "np.random.seed(6789)\n",
        "import warnings  # In order not to show warning\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import collections\n",
        "from six.moves import range\n",
        "from six.moves.urllib.request import urlretrieve\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "class DataManager:\n",
        "    def __init__(self, verbose=True, maxlen= 50, random_state=6789):\n",
        "        self.verbose = verbose\n",
        "        self.max_sentence_len = 0\n",
        "        self.str_questions = list()\n",
        "        self.str_labels = list()\n",
        "        self.numeral_labels = list()\n",
        "        self.maxlen = maxlen\n",
        "        self.numeral_data = list()\n",
        "        self.random_state = random_state\n",
        "        self.random = np.random.RandomState(random_state)\n",
        "\n",
        "    @staticmethod\n",
        "    def maybe_download(dir_name, file_name, url, verbose= True):\n",
        "        if not os.path.exists(dir_name):\n",
        "            os.mkdir(dir_name)\n",
        "        if not os.path.exists(os.path.join(dir_name, file_name)):\n",
        "            urlretrieve(url + file_name, os.path.join(dir_name, file_name))\n",
        "        if verbose:\n",
        "            print(\"Downloaded successfully {}\".format(file_name))\n",
        "\n",
        "    def read_data(self, dir_name, file_names):\n",
        "        self.str_questions= list(); self.str_labels= list()\n",
        "        for file_name in file_names:\n",
        "            file_path= os.path.join(dir_name, file_name)\n",
        "            with open(file_path, \"r\", encoding=\"latin-1\") as f:\n",
        "                for row in f:\n",
        "                    row_str= row.split(\":\")\n",
        "                    label, question= row_str[0], row_str[1]\n",
        "                    question= question.lower()\n",
        "                    self.str_labels.append(label)\n",
        "                    self.str_questions.append(question[0:-1])\n",
        "                    if self.max_sentence_len < len(self.str_questions[-1]):\n",
        "                        self.max_sentence_len= len(self.str_questions[-1])\n",
        "\n",
        "        # turns labels into numbers\n",
        "        le= preprocessing.LabelEncoder()\n",
        "        le.fit(self.str_labels)\n",
        "        self.numeral_labels = np.array(le.transform(self.str_labels))\n",
        "        self.str_classes= le.classes_\n",
        "        self.num_classes= len(self.str_classes)\n",
        "        if self.verbose:\n",
        "            print(\"\\nSample questions... \\n\")\n",
        "            print(self.str_questions[0:5])\n",
        "            print(\"Labels {}\\n\\n\".format(self.str_classes))\n",
        "\n",
        "    def manipulate_data(self):\n",
        "        tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "        tokenizer.fit_on_texts(self.str_questions)\n",
        "        self.numeral_data = tokenizer.texts_to_sequences(self.str_questions)\n",
        "        self.numeral_data = tf.keras.preprocessing.sequence.pad_sequences(self.numeral_data, padding='post', truncating= 'post', maxlen= self.maxlen)\n",
        "        self.word2idx = tokenizer.word_index\n",
        "        self.word2idx = {k:v for k,v in self.word2idx.items()}\n",
        "        self.idx2word = {v:k for k,v in self.word2idx.items()}\n",
        "        self.vocab_size = len(self.word2idx)\n",
        "\n",
        "    def train_valid_split(self, train_ratio=0.9):\n",
        "        idxs = np.random.permutation(np.arange(len(self.str_questions)))\n",
        "        train_size = int(train_ratio*len(idxs)) +1\n",
        "        self.train_str_questions, self.valid_str_questions = self.str_questions[0:train_size], self.str_questions[train_size:]\n",
        "        self.train_numeral_data, self.valid_numeral_data = self.numeral_data[0:train_size], self.numeral_data[train_size:]\n",
        "        self.train_numeral_labels, self.valid_numeral_labels = self.numeral_labels[0:train_size], self.numeral_labels[train_size:]\n",
        "        self.tf_train_set = tf.data.Dataset.from_tensor_slices((self.train_numeral_data, self.train_numeral_labels))\n",
        "        self.tf_valid_set = tf.data.Dataset.from_tensor_slices((self.valid_numeral_data, self.valid_numeral_labels))"
      ],
      "metadata": {
        "id": "Gd6VO_b8GUbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Loading data...')\n",
        "DataManager.maybe_download(\"Data\", \"train_1000.label\", \"http://cogcomp.org/Data/QA/QC/\")\n",
        "DataManager.maybe_download(\"Data\", \"TREC_10.label\", \"http://cogcomp.org/Data/QA/QC/\")\n",
        "\n",
        "dm = DataManager(maxlen=100)\n",
        "dm.read_data(\"Data/\", [\"train_1000.label\", \"TREC_10.label\"])   # read data\n",
        "# If you want to play around with a bigger dataset, you can try train_set.label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgaVeGBGGV0i",
        "outputId": "9f4ea024-68d3-4797-cc52-ea2dc0405134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Downloaded successfully train_1000.label\n",
            "Downloaded successfully TREC_10.label\n",
            "\n",
            "Sample questions... \n",
            "\n",
            "['manner how did serfdom develop in and then leave russia ?', 'cremat what films featured the character popeye doyle ?', \"manner how can i find a list of celebrities ' real names ?\", 'animal what fowl grabs the spotlight after the chinese year of the monkey ?', 'exp what is the full form of .com ?']\n",
            "Labels ['ABBR' 'DESC' 'ENTY' 'HUM' 'LOC' 'NUM']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model_name = 'small_bert/bert_en_uncased_L-2_H-128_A-2'  #@param [\"bert_en_uncased_L-12_H-768_A-12\", \"bert_en_cased_L-12_H-768_A-12\",\n",
        "                                                              #\"bert_multi_cased_L-12_H-768_A-12\", \"small_bert/bert_en_uncased_L-2_H-128_A-2\",\n",
        "                                                              #\"small_bert/bert_en_uncased_L-2_H-256_A-4\", \"small_bert/bert_en_uncased_L-2_H-512_A-8\",\n",
        "                                                              #\"small_bert/bert_en_uncased_L-2_H-768_A-12\", \"small_bert/bert_en_uncased_L-4_H-128_A-2\", \"small_bert/bert_en_uncased_L-4_H-256_A-4\", \"small_bert/bert_en_uncased_L-4_H-512_A-8\", \"small_bert/bert_en_uncased_L-4_H-768_A-12\", \"small_bert/bert_en_uncased_L-6_H-128_A-2\", \"small_bert/bert_en_uncased_L-6_H-256_A-4\", \"small_bert/bert_en_uncased_L-6_H-512_A-8\", \"small_bert/bert_en_uncased_L-6_H-768_A-12\", \"small_bert/bert_en_uncased_L-8_H-128_A-2\", \"small_bert/bert_en_uncased_L-8_H-256_A-4\", \"small_bert/bert_en_uncased_L-8_H-512_A-8\", \"small_bert/bert_en_uncased_L-8_H-768_A-12\", \"small_bert/bert_en_uncased_L-10_H-128_A-2\", \"small_bert/bert_en_uncased_L-10_H-256_A-4\", \"small_bert/bert_en_uncased_L-10_H-512_A-8\", \"small_bert/bert_en_uncased_L-10_H-768_A-12\", \"small_bert/bert_en_uncased_L-12_H-128_A-2\", \"small_bert/bert_en_uncased_L-12_H-256_A-4\", \"small_bert/bert_en_uncased_L-12_H-512_A-8\", \"small_bert/bert_en_uncased_L-12_H-768_A-12\", \"albert_en_base\", \"electra_small\", \"electra_base\", \"experts_pubmed\", \"experts_wiki_books\", \"talking-heads_base\"]\n",
        "\n",
        "map_name_to_handle = {\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
        "}\n",
        "\n",
        "map_model_to_preprocess = {\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "}\n",
        "\n",
        "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
        "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
        "\n",
        "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
        "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEGasz1UGjnJ",
        "outputId": "36031473-87fc-4e46-8e1a-f5be7ef5146f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1\n",
            "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization  # to create AdamW optimizer\n",
        "import matplotlib.pyplot as plt\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "global_seed = 123\n",
        "np.random.seed(global_seed)\n",
        "tf.random.set_seed(global_seed)"
      ],
      "metadata": {
        "id": "64VKwvNKGwyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
      ],
      "metadata": {
        "id": "0NLYVL2SGkD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dm.manipulate_data()\n",
        "dm.train_valid_split(train_ratio=0.8)"
      ],
      "metadata": {
        "id": "34-ztCNbJhn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_preprocessed = bert_preprocess_model(dm.train_str_questions)\n",
        "\n",
        "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
        "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
        "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
        "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
        "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTfmTSjLJIPX",
        "outputId": "505feb5d-3451-4ca3-c98f-ac14ed88f8fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys       : ['input_mask', 'input_type_ids', 'input_word_ids']\n",
            "Shape      : (1201, 128)\n",
            "Word Ids   : [  101  5450  2129  2106 14262  2546  9527  4503  1999  1998  2059  2681]\n",
            "Input Mask : [1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
      ],
      "metadata": {
        "id": "UuBio0e4MO60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_results = bert_model(text_preprocessed)\n",
        "\n",
        "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
        "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
        "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
        "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
        "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-jgjLlXMSf4",
        "outputId": "a4f166c8-9688-4a8c-9c1a-ee11d4b65096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1\n",
            "Pooled Outputs Shape:(1201, 128)\n",
            "Pooled Outputs Values:[-0.9999874   0.15125254 -0.9991584  -0.00699307 -0.9997165  -0.19091925\n",
            " -0.9965237   0.7653005   0.08639494 -0.05611859 -0.6970136  -0.0929099 ]\n",
            "Sequence Outputs Shape:(1201, 128, 128)\n",
            "Sequence Outputs Values:[[-1.1960251   0.20461899 -4.3314643  ... -0.34651375 -1.2260898\n",
            "   0.96840656]\n",
            " [-1.6841075   1.6412406  -0.6510462  ... -1.264416   -1.7317116\n",
            "   0.29814124]\n",
            " [-1.3228791   0.0855017  -0.70905286 ... -1.4628998  -1.012091\n",
            "   0.7663966 ]\n",
            " ...\n",
            " [-0.2809335   0.34718785 -0.72980344 ... -1.4662099  -1.2506759\n",
            "   1.6497993 ]\n",
            " [-0.53542495  0.04995675 -1.2849635  ... -2.299842   -0.7948264\n",
            "   0.97378993]\n",
            " [-0.06455973  0.42019683 -1.0588249  ... -1.7363688  -1.9657958\n",
            "   2.5716949 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nTB-yFqgMS6e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}